{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Working with RDDs (5 points)\n",
    "\n",
    "This is an interactive PySpark session. Remember that when you open this notebook the `SparkContext` and `SparkSession` are already created, and they are in the `sc` and `spark` variables, respectively. You can run the following two cells to make sure that the Kernel is active.\n",
    "\n",
    "**Do not insert any additional cells than the ones that are provided.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-81-108.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-81-108.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdff1f42cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, make an RDD called `top1m` that contains the contents of the file `top-1m.csv` that you placed into the cluster's HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1m = sc.textFile(\"/user/hadoop/top-1m.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one element in the RDD for each line in the file. The `.count()` method will compute how many lines are in the file. In the following cell, type the expression to count the lines in the `top1m` RDD. Run the cell and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1m.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the `.com` domains\n",
    "\n",
    "How many of the websites in this RDD are in the .com domain?\n",
    "\n",
    "In the following cell, write a code snippet that finds the records with `.com` and counts them. (Hint: use a regular expression.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'number of records with .com': 490422,\n",
       "             'number of records without .com': 509578})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "com_re = re.compile(\"\\.com$\")\n",
    "\n",
    "def extract(line):\n",
    "    m = com_re.search(line)\n",
    "    if m:\n",
    "        return \"number of records with .com\"\n",
    "    else:\n",
    "        return \"number of records without .com\"\n",
    "    \n",
    "dotcom = top1m.map( lambda line: [ extract( line ), 1 ])\n",
    "\n",
    "dotcom.countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram the Top Level Domains (TLDs)\n",
    "\n",
    "What is the distribution of TLDs in the top 1 million websites? We can quickly compute this using the RDD function `countByValue()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, write a function called `tld` (in Python) that takes a domain name string and outputs the top-level domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tld(name):\n",
    "    return(name.split(\".\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, map the `top1m` RDD using `tld` into a new RDD called `tlds`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlds = top1m.map( lambda line: tld(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following two cells, evaluate `top1m.first()` and  `tlds.first()` to see if the first line of `top1m` transformed by `tld` is properly represented as the first line of `tlds`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1,youtube.com'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1m.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'com'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlds.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 50 elements of `top1m` by evaluating `top1m.take(50)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1,youtube.com',\n",
       " u'2,google.com',\n",
       " u'3,facebook.com',\n",
       " u'4,baidu.com',\n",
       " u'5,wikipedia.org',\n",
       " u'6,reddit.com',\n",
       " u'7,yahoo.com',\n",
       " u'8,google.co.in',\n",
       " u'9,qq.com',\n",
       " u'10,taobao.com',\n",
       " u'11,sohu.com',\n",
       " u'12,tmall.com',\n",
       " u'13,amazon.com',\n",
       " u'14,twitter.com',\n",
       " u'15,vk.com',\n",
       " u'16,instagram.com',\n",
       " u'17,sina.com.cn',\n",
       " u'18,google.co.jp',\n",
       " u'19,live.com',\n",
       " u'20,jd.com',\n",
       " u'21,360.cn',\n",
       " u'22,weibo.com',\n",
       " u'23,yandex.ru',\n",
       " u'24,google.co.uk',\n",
       " u'25,google.com.br',\n",
       " u'26,netflix.com',\n",
       " u'27,google.de',\n",
       " u'28,twitch.tv',\n",
       " u'29,google.ru',\n",
       " u'30,google.fr',\n",
       " u'31,login.tmall.com',\n",
       " u'32,pornhub.com',\n",
       " u'33,alipay.com',\n",
       " u'34,xvideos.com',\n",
       " u'35,google.com.hk',\n",
       " u'36,google.it',\n",
       " u'37,google.es',\n",
       " u'38,google.com.mx',\n",
       " u'39,ebay.com',\n",
       " u'40,bing.com',\n",
       " u'41,yahoo.co.jp',\n",
       " u'42,google.ca',\n",
       " u'43,t.co',\n",
       " u'44,hao123.com',\n",
       " u'45,ok.ru',\n",
       " u'46,microsoft.com',\n",
       " u'47,pages.tmall.com',\n",
       " u'48,wikia.com',\n",
       " u'49,mail.ru',\n",
       " u'50,imgur.com']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1m.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the same thing with the `tlds` RDD to make sure that the first 50 lines were properly transformed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'org',\n",
       " u'com',\n",
       " u'com',\n",
       " u'in',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'cn',\n",
       " u'jp',\n",
       " u'com',\n",
       " u'com',\n",
       " u'cn',\n",
       " u'com',\n",
       " u'ru',\n",
       " u'uk',\n",
       " u'br',\n",
       " u'com',\n",
       " u'de',\n",
       " u'tv',\n",
       " u'ru',\n",
       " u'fr',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'hk',\n",
       " u'it',\n",
       " u'es',\n",
       " u'mx',\n",
       " u'com',\n",
       " u'com',\n",
       " u'jp',\n",
       " u'ca',\n",
       " u'co',\n",
       " u'com',\n",
       " u'ru',\n",
       " u'com',\n",
       " u'com',\n",
       " u'com',\n",
       " u'ru',\n",
       " u'com']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlds.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, `tlds.countByValue()` would give us a list of each TLD and the number of times that it appears in the top1m file. Note that this function returns the results as a `defaultDict` in the Python environemnt, not as an RDD. But we want it reverse sorted by count. To do this, we can set a variable called `tlds_and_counts` equal to `tlds.countByValue()` and then reverse the order, sort, and take the top 50, like this:\n",
    "\n",
    "```\n",
    "tlds_and_counts = tlds.countByValue()\n",
    "counts_and_tlds = [(count,domain) for (domain,count) in tlds_and_counts.items()]\n",
    "```\n",
    "\n",
    "In the following cell, run the code above to produce the Python Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlds_and_counts = tlds.countByValue()\n",
    "counts_and_tlds = [(count,domain) for (domain,count) in tlds_and_counts.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, reverse sort `counts_and_tlds` and display the first 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(490422, u'com'),\n",
       " (48554, u'org'),\n",
       " (45130, u'ru'),\n",
       " (42911, u'net'),\n",
       " (28239, u'de'),\n",
       " (20067, u'br'),\n",
       " (17312, u'uk'),\n",
       " (15470, u'ir'),\n",
       " (13488, u'pl'),\n",
       " (12789, u'in'),\n",
       " (11318, u'au'),\n",
       " (10655, u'fr'),\n",
       " (10649, u'it'),\n",
       " (9000, u'info'),\n",
       " (8018, u'es'),\n",
       " (6946, u'nl'),\n",
       " (6811, u'jp'),\n",
       " (6810, u'gr'),\n",
       " (6738, u'ca'),\n",
       " (6524, u'cz'),\n",
       " (6503, u'mx'),\n",
       " (6490, u'co'),\n",
       " (6236, u'ua'),\n",
       " (5239, u'tw'),\n",
       " (5230, u'se'),\n",
       " (5064, u'io'),\n",
       " (4743, u'eu'),\n",
       " (4365, u'cn'),\n",
       " (3831, u'hu'),\n",
       " (3806, u'me'),\n",
       " (3711, u'tv'),\n",
       " (3710, u'dk'),\n",
       " (3536, u'za'),\n",
       " (3486, u'ch'),\n",
       " (3479, u'sk'),\n",
       " (3187, u'us'),\n",
       " (3179, u'ar'),\n",
       " (3152, u'kr'),\n",
       " (3110, u'ro'),\n",
       " (3090, u'id'),\n",
       " (3069, u'vn'),\n",
       " (2920, u'no'),\n",
       " (2832, u'edu'),\n",
       " (2783, u'at'),\n",
       " (2776, u'cl'),\n",
       " (2759, u'be'),\n",
       " (2569, u'tr'),\n",
       " (2325, u'biz'),\n",
       " (2117, u'pt'),\n",
       " (1979, u'xyz')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_and_tlds.sort(reverse=True)\n",
    "counts_and_tlds[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** `top1m.collect()[0:50]` and `top1m.take(50)` produce the same result. Which one is more efficient and why? Put your answer in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functoin call \"top1m.take(50)\" is more efficient. Because .collect() implies gathering and .take() does not. The function .take() means to accept. When the collect operation is used on an RDD, the dataset is being copied to the driver, in our case is the master node. A memory exception will be trown if the the collected data is too large to fit in memory. Take function can be used to get capped number of elements instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you finish this problem, click on the File -> 'Save and Checkpoint' in the menu bar to make sure that the latest version of the workbook file is saved. Also, before you close this notebook and move on, make sure you disconnect your SparkContext, otherwise you will not be able to re-allocate resources. Remember, you will commit the .ipynb file to the repository for submission (in the master node terminal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
