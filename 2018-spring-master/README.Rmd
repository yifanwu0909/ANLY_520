---
output:
  md_document:
    variant: gfm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

**This syllabus is effective as of `r strftime(Sys.time(), "%A,  %B %d, %Y at %I:%M %p", tz = "America/New_York")`**

# ANLY502 <br/> Massive Data Fundamentals <br/> Georgetown University <br/> Spring 2018

## Course Information

- **Instructors:** Marck Vaisman (mv559 at georgetown.edu), Irina Vayndiner (iv95 at georgetown.edu) 
- **Classroom:** Car Barn 203
- **Time:** Monday 6:30-9:00pm (except 1/10 which meets on a Wednesday)
- **TA's:** 
  - Tiankai Guo (tg550 at georgetown.edu)
  - Jiahao Xu (jx94 at georgetown.edu) 
- **TA Office Hours:**
  - Tue 7:00-9:00pm at Graduate Student Loungem, Car Barn
  - Wed 9:30-11:30am at Car Barn 171
  - Thurs 4:00-6:00pm at Car Barn 171

## Course Description

Data is everywhere! Many times, it's just too big to work with traditional tools. This is a hands-on, practical workshop style course about using cloud computing resources to do analysis and manipulation of datasets that are too large to fit on a single machine and/or analyzed with traditional tools. The course will focus on Spark, MapReduce, the Hadoop Ecosystem and other tools.

You will understand how to acquire and/or ingest the data, and then massage, clean, transform, analyze, and model it within the context of big data analytics. You will be able to think more programmatically and logically about your big data needs, tools and issues. 

## Credit Hours

This is a 3 credit graduate course. You will spend approximately 3 hours per week in class. It is expected that you will spend approximately 2-3 hours of outside classroom activities (required readings, homework problems, completion of labs, quizzes, etc.) for each hour of class time. You will spend 36 hours in instructional time, and approximately 100 hours in out-of-classroom time.

## Course Objectives

- Operate big data tools and cloud infrastructure, including Spark, MapReduce, Hadoop and other tools in the big data ecosystem 
- Recognize and use ancillary tools that support big data processing, including git and the Linux command line
- Setup and manage big data infrastructure and tools in the cloud on Amazon Web Services and Microsoft Azure
- Identify broad spectrum resources and documentation to remain current with big data tools and developments
- Execute a big data analytics exercise from start to finish: ingest, wrangle, clean, analyze and store
- Be aware of the responsibilities that are associated with performing analysis of large datasets 

## Prerequisites

### Essential
- Experience with R, Python, and SQL for reading files, manipulating and analyzing data. **Note:** We will use Python as the primary interface to Apache Spark, through [PySpark](https://spark.apache.org/docs/0.9.0/python-programming-guide.html)
- Understand programming concepts (flow control, input/output, variable assignment.) - Experience with git and GitHub

### Optional and Useful

- Experience with the command line and terminal shell to navigate the file system, manipulate files (create, move, delete, etc.). Understand file permissions
- Experience with remote computing via ssh
- Understand shell executables

### Refresher Tutorials

It is highly recommended that you go through the following tutorials if you need a refresher or are new to the topics of git, the command line, and SQL.

- [git - the simple guide](http://rogerdudler.github.io/git-guide/)
- [DataCamp: Introduction to Git for Data Science](https://www.datacamp.com/courses/introduction-to-git-for-data-science)
- [DataCamp: Introduction to Shell for Data Science](https://www.datacamp.com/courses/introduction-to-shell-for-data-science)
- [DataCamp: Introduction to SQL for Data Science](https://www.datacamp.com/courses/intro-to-sql-for-data-science)

# Course Materials

We have chosen several reference books for this course that cover different parts of the material. We will assign readings for each class from these books. These books are all available on [Safari Books Online](https://www.safaribooksonline.com/), and you should be able to access these resources. Our understanding is that as a Georgetown student, you have access to these resources. Visit the [Georgetown Library e-book information page](https://guides.library.georgetown.edu/ebooks) for additional information and click on "Safari Books Online".  

We may also provide supplemental materials to complement the books. Articles, links, etc., will be posted on Canvas.

## Books (for assigned readings)

- Benjamin Bengfort, Jenny Kim (2016). _Data Analytics with Hadoop: An Introduction for Data Scientists_. O'Reilly Media. ISBN: 9781491913703.
- Bill Chambers, Matei Zaharia (2018). _Spark: The Definitive Guide_. O'Reilly Media. ISBN: 9781491912218.

## Additional Recommended Books

- Tomasz Drabas, Denny Lee (2017). _Learning Pyspark_. Packt Publishing. ISBN: 9781786463708.
- Ofer Mendelevitch, Casey Stella, Douglas Eadline (2016). _Practical Data Science with Hadoop and Spark: Designing and Building Effective Analytics at Scale_. Addison-Wesley Professional. ISBN: 9780134024141.
- Krishna Sankar (2016). _Fast Data Processing with Spark 2 - Third Edition_. Packt Publishing. ISBN: 9781784392574.

# Learning Activities and Evaluation

This is a hands-on, practical, workshop style course that provides opportunities to use the tools and techniques discussed in class. Although this is not a programming course per se, there is programming involved. 

## Lectures and In-Class Labs

Every class session will have a lecture portion and many sessions will have an in-class lab portion. Lab exercises are designed to get you familiar with the tools discussed in class. In these labs, we will work through simple examples. The completion of the in-class lab exercises is part of your attendance/participation portion of the grade. 

## Quizzes

There will be a total of 6 online quizzes about the topics/ideas discussed in class and from the readings. The purpose of the quizzes is to reinforce your knowledge about the tools and platform and also to help you remember the nomenclature and terms used in class. The quizzes will be online through [Canvas](http://canvas.georgetown.edu) and you can take them at your convenience within the established time window. In lieu of a final exam, there will be a longer in-class quiz that is worth more points during the last class session.

## Assignments

You will be given problem sets as homework assignments. The goal of these problem sets is to use the big data tools to answer some questions about large datasets. The problem sets will build on the labs and will be much more elaborate. Deliverables from the problem sets will usually include code written for your programs and the output produced.

We will be using [GitHub Classroom](https://classroom.github.com/) for problem sets and assignment submissions. When an assignment is created, we will email you a link that will clone the assignment and create a private repository for you. You will perform your work within the repository and then push back to GitHub for submission. If you do not have a [GitHub](http://www.github.com) account, please create one.

## Grading

- Problem Sets: 60% (6 problem sets, 10% each)
- Quizzes: 30% total (5 online quizzes worth 4% or 5% each, 1 online in-class quiz worth 9%)
- Attendance/Participation: 10% (attendance, in-class discussion, completion of in-class labs, active participation in online forums)

# Course Calendar 

This calendar is subject to change. We will make make any changes known in advance.

```{r, echo = FALSE, results="asis"} 
source("schedule.R")
sched %>%
  mutate(date = format(date, "%b %d")) %>%
  knitr:::kable(., "markdown",
                col.names = c("Date", "Session", "Title", "Topics", 
                              "Lab", "Reading", "Assignment", "Quiz")
  )
``` 

**Class will not meet on Jan 15 (MLK Holiday), Feb 19 (President's Day), Mar 05 (Spring Break), Apr 02 (Easter Break).**

The topics for the last 4 sessions are placeholders, and it is very likely we will cover these topics. However, we have some room for flexibility depending on other topics of interest to the class. We may also have a guest lecturer from time to time.

# Policies & Expectations

- **Attendance:** Given the technical nature of this course, and the breadth of topics discussed, you must attend every class session. **Attendance will be tracked and a sign-in sheet will be provided.** Attendance counts towards 10% of your grade. Please contact us in advance if you are not able to attend class. Excused absences in advance will not affect your attendance grade. 
- **E-mail:** We will try to respond to email within 24 to 36 hours. Please use email for personal discussions and not for course questions.
- **Online Discussion Boards:** Please use the discussion board on Canvas for questions about the course, homework assignments, technical issues, etc. Individual questions submitted by email do not scale, and the likelihood of many students having the same question is high. Using the forums is a great resource for everyone.
- **Name Tents:** You will be given a name tent. Please use it every class session and place it in front of you so we can get to know your name quicker.

# Open Door Policy

Please approach or get in touch with us if something is not working for you regarding the class, methods, etc. Our pledge to you is to provide the best learning experience possible.

# Academic Integrity

You must perform all of your own work on problem sets. You may collaborate with other students, though all submitted work must be your own. Please refer to the [Georgetown University Honor Council](https://honorcouncil.georgetown.edu/system/policies) site for additional information.
